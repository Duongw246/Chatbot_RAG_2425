import time
import random
import streamlit as st
from seed_data import postgres_retriever
from agent import (legal_response, 
                   normal_response, 
                   query_transform,
                #    history_response,
                   get_router
                   )
# from langchain_community.callbacks.streamlit import StreamlitCallbackHandler
from langchain_community.chat_message_histories import StreamlitChatMessageHistory

def reset_conversation():
    """
    ƒê·∫∑t l·∫°i to√†n b·ªô tr·∫°ng th√°i c·ªßa cu·ªôc tr√≤ chuy·ªán.
    """
    st.session_state['messages'] = [
        {"role": "assistant", "content": random.choice(
            [
                "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω ph√°p l√Ω c·ªßa b·∫°n. H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v√†o √¥ b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu tr√≤ chuy·ªán v·ªõi t√¥i.",
                "Ch√†o b·∫°n! B·∫°n c·∫ßn t√¥i gi√∫p g√¨ kh√¥ng? T√¥i c√≥ th·ªÉ tr·∫£ l·ªùi m·ªçi c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ lu·∫≠t giao th√¥ng ƒë∆∞·ªùng b·ªô c·ªßa b·∫°n.",
                "B·∫°n mu·ªën bi·∫øt g√¨ v·ªÅ lu·∫≠t giao th√¥ng ƒë∆∞·ªùng b·ªô? H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v√†o √¥ b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu tr√≤ chuy·ªán v·ªõi t√¥i.",
        ])}
    ] 

def response_generator(response):
    for word in response.split():
        yield word + " "
        time.sleep(0.05)
    
def setup_page():
    """
    C·∫•u h√¨nh trang web c∆° b·∫£n
    """
    st.set_page_config(
        page_title="Legal Assistant", 
        page_icon="üí¨",
        layout="wide" 
    )

def setup_sidebar():
    with st.sidebar:
        st.markdown("""
        <h1 style='text-align: center; color: #4CAF50;'>‚öôÔ∏è C·∫•u H√¨nh</h1>
        """, unsafe_allow_html=True)
        
        with st.expander("üöÄ Ch·ªçn Model AI", expanded=True):
            model_choice = st.selectbox(
                "Ch·ªçn Model ƒë·ªÉ tr·∫£ l·ªùi:",
                ["vertex-gemini-1.5-pro", "vertex-gemini-1.5-flash", "gemini-1.5-pro", "gemini-1.5-flash"],
                index=0
            )
            st.caption("üîπ Model AI s·∫Ω ·∫£nh h∆∞·ªüng ƒë·∫øn t·ªëc ƒë·ªô v√† ƒë·ªô ch√≠nh x√°c c·ªßa c√¢u tr·∫£ l·ªùi.")
        
        with st.expander("üìÇ Ch·ªçn ngu·ªìn d·ªØ li·ªáu", expanded=True):
            data_source = st.radio(
                "∆Øu ti√™n ngu·ªìn d·ªØ li·ªáu:",
                ["∆Øu ti√™n lu·∫≠t m·ªõi", "Ch·ªâ d√πng d·ªØ li·ªáu c≈©", "K·∫øt h·ª£p c·∫£ hai"],
                index=2
            )
            st.caption("üîπ Ch·ªçn c√°ch h·ªá th·ªëng l·∫•y d·ªØ li·ªáu t·ª´ RAG.")
        
        with st.expander("üìú Ch·ªçn b·ªô lu·∫≠t ho·∫∑c ch·ªß ƒë·ªÅ"):
            law_topic = st.selectbox(
                "Ch·ªçn ch·ªß ƒë·ªÅ lu·∫≠t:",
                ["Giao th√¥ng ƒë∆∞·ªùng b·ªô"],
                index=0
            )
        
        with st.expander("üîç ƒêi·ªÅu ch·ªânh truy v·∫•n"):
            retrieval_depth = st.slider("Ch·ªçn ƒë·ªô s√¢u truy v·∫•n:", 1, 10, 10)
            st.caption("üîπ ƒê·ªô s√¢u c√†ng cao, truy xu·∫•t c√†ng nhi·ªÅu t√†i li·ªáu.")
        
        with st.expander("üõ† Tu·ª≥ Ch·ªçn Kh√°c"):
            if st.button("üóë X√≥a cu·ªôc tr√≤ chuy·ªán", use_container_width=True):
                reset_conversation()
            st.markdown("""
            <small style='color: grey;'>X√≥a l·ªãch s·ª≠ chat ƒë·ªÉ b·∫Øt ƒë·∫ßu cu·ªôc tr√≤ chuy·ªán m·ªõi.</small>
            """, unsafe_allow_html=True)
        
    return model_choice, data_source, law_topic, retrieval_depth


        
def setup_chat_interface(model_choice):
    st.title("Legal Assistant")
    if model_choice == "vertex-gemini-1.5-pro" or model_choice == "vertex-gemini-1.5-flash":
        st.caption("Tr·ª£ l√Ω AI ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi LangChain v√† Vertex AI")
    if model_choice == "gemini-1.5-pro" or model_choice == "gemini-1.5-flash":
        st.caption("Tr·ª£ l√Ω AI ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi LangChain v√† Google")

    msgs = StreamlitChatMessageHistory(key="langchain_messages")
    if "messages" not in st.session_state:
        st.session_state['messages'] = [
            {"role": "assistant", "content": random.choice(
                [
                    "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω ph√°p l√Ω c·ªßa b·∫°n. H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v√†o √¥ b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu tr√≤ chuy·ªán v·ªõi t√¥i.",
                    "Ch√†o b·∫°n! B·∫°n c·∫ßn t√¥i gi√∫p g√¨ kh√¥ng? T√¥i c√≥ th·ªÉ tr·∫£ l·ªùi m·ªçi c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ lu·∫≠t giao th√¥ng ƒë∆∞·ªùng b·ªô c·ªßa b·∫°n.",
                    "B·∫°n mu·ªën bi·∫øt g√¨ v·ªÅ lu·∫≠t giao th√¥ng ƒë∆∞·ªùng b·ªô? H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v√†o √¥ b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu tr√≤ chuy·ªán v·ªõi t√¥i.",
            ])}
        ]
        msgs.add_ai_message(st.session_state.messages[0]["content"])
    
    for msg in st.session_state['messages']:
        with st.chat_message(msg["role"]):
            # response = st.markdown_stream(response_generator(msg["content"]))
            st.markdown(msg["content"])
    return msgs

def user_input(msgs, model_choice, new_retriever, old_retriever):
    if prompt:= st.chat_input("H√£y h·ªèi t√¥i b·∫•t c·ª© ƒëi·ªÅu g√¨ v·ªÅ lu·∫≠t giao th√¥ng ƒë∆∞·ªùng b·ªô!"):
        st.session_state['messages'].append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)   
        msgs.add_user_message(prompt)
        router = get_router(prompt, model_choice)
        router, status = router.split(",")
        router = router.strip(" ")
        status = status.strip(" ")
        # st.markdown(router)
        # st.markdown(status)
        transform_prompt = query_transform(prompt, model_choice)
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            timer_placeholder = st.empty()
            start_time = time.time()
            with st.spinner("ƒêang t√¨m ki·∫øm th√¥ng tin..."):
                def update_timer():
                    while True:
                        elapsed_time = time.time() - start_time
                        timer_placeholder.caption(f"‚è±Ô∏è ƒêang x·ª≠ l√Ω: {elapsed_time:.2f} gi√¢y")
                        time.sleep(0.1)

                import threading
                timer_thread = threading.Thread(target=update_timer, daemon=True)
                timer_thread.start()
                chat_history = [
                    {"role": msg["role"], "content": msg["content"]}
                    for msg in st.session_state.messages[:-1]
                ]
                if router == "yes":
                    if status == "new":
                        context = new_retriever.invoke(transform_prompt)
                        
                    elif status == "old":
                        context = old_retriever.invoke(transform_prompt)

                    response = legal_response(msgs, model_choice, context, chat_history)
                        
                elif router == "no":
                    response = normal_response(transform_prompt, model_choice, chat_history)
                    
                else:
                    response = random.choice([
                    "C√¢u h·ªèi c·ªßa b·∫°n n·∫±m kh√¥ng n·∫±m trong ph·∫°m vi v·ªÅ lu·∫≠t giao th√¥ng ƒë∆∞·ªùng b·ªô. H√£y nh·∫≠p c√¢u h·ªèi kh√°c ƒë·ªÉ t√¥i gi√∫p b·∫°n nh√©!",
                    "Xin l·ªói, c√¢u h·ªèi n√†y kh√¥ng n·∫±m trong ph·∫°m vi c·ªßa t√¥i. H√£y nh·∫≠p c√¢u h·ªèi kh√°c ƒë·ªÉ t√¥i gi√∫p b·∫°n nh√©!",
                    "Ki·∫øn th·ª©c c·ªßa t√¥i ch·ªâ gi·ªõi h·∫°n trong lƒ©nh v·ª±c lu·∫≠t giao th√¥ng ƒë∆∞·ªùng b·ªô. H√£y nh·∫≠p c√¢u h·ªèi kh√°c ƒë·ªÉ t√¥i gi√∫p b·∫°n nh√©!",
                ])  
                response_content = ""
                for chunk in response:
                    for char in chunk:
                        response_content += char
                        response_placeholder.markdown(response_content)
                end_time = time.time()  # K·∫øt th√∫c ƒëo th·ªùi gian
                elapsed_time = end_time - start_time    
                st.session_state['messages'].append({"role": "assistant", "content": response})
                msgs.add_ai_message(response)
                elapsed_time = time.time() - start_time
                timer_placeholder.caption(f"‚è±Ô∏è Th·ªùi gian ph·∫£n h·ªìi: {elapsed_time:.2f} gi√¢y")
def main():
    setup_page()
    model_choice = setup_sidebar()
    new_retriever = postgres_retriever(collection_name="vectordb", database_name="postgres")
    old_retriever = postgres_retriever(collection_name="old_vectordb", database_name="old_law")
    msgs = setup_chat_interface(model_choice)
    user_input(msgs, model_choice, new_retriever, old_retriever)
    
if __name__ == "__main__":
    main()