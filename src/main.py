import time
import random
import streamlit as st
from seed_data import postgres_retriever
from agent import (legal_response, 
                   normal_response, 
                   query_transform,
                #    history_response,
                   get_router
                   )
# from langchain_community.callbacks.streamlit import StreamlitCallbackHandler
from langchain_community.chat_message_histories import StreamlitChatMessageHistory

def reset_conversation():
    """
    ƒê·∫∑t l·∫°i to√†n b·ªô tr·∫°ng th√°i c·ªßa cu·ªôc tr√≤ chuy·ªán.
    """
    st.session_state['messages'] = [
        {"role": "assistant", "content": random.choice(
            [
                "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω ph√°p l√Ω c·ªßa b·∫°n. H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v√†o √¥ b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu tr√≤ chuy·ªán v·ªõi t√¥i.",
                "Ch√†o b·∫°n! B·∫°n c·∫ßn t√¥i gi√∫p g√¨ kh√¥ng? T√¥i c√≥ th·ªÉ tr·∫£ l·ªùi m·ªçi c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ lu·∫≠t giao th√¥ng ƒë∆∞·ªùng b·ªô c·ªßa b·∫°n.",
                "B·∫°n mu·ªën bi·∫øt g√¨ v·ªÅ lu·∫≠t giao th√¥ng ƒë∆∞·ªùng b·ªô? H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v√†o √¥ b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu tr√≤ chuy·ªán v·ªõi t√¥i.",
        ])}
    ] 

def response_generator(response):
    for word in response.split():
        yield word + " "
        time.sleep(0.05)
    
def setup_page():
    """
    C·∫•u h√¨nh trang web c∆° b·∫£n
    """
    st.set_page_config(
        page_title="Legal Assistant", 
        page_icon="üí¨",
        layout="wide" 
    )

def setup_sidebar():
    with st.sidebar:
        st.title("‚öôÔ∏è **C·∫§U H√åNH**")
        st.header(":desktop_computer: Response Model")
        model_choice = st.radio(
            "Ch·ªçn Model ƒë·ªÉ tr·∫£ l·ªùi:",
            ["Vertex", "Gemini"]
        )
        
        st.button("Clear chat", on_click=reset_conversation)
        return model_choice
        
def setup_chat_interface(model_choice):
    if model_choice == "Gemini":
        st.title("Legal Assistant")
        st.caption("Tr·ª£ l√Ω AI ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi LangChain v√† Google")
    if model_choice == "Vertex":
        st.title("Legal Assistant")
        st.caption("Tr·ª£ l√Ω AI ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi LangChain v√† Vertex AI")

    msgs = StreamlitChatMessageHistory(key="langchain_messages")
    if "messages" not in st.session_state:
        st.session_state['messages'] = [
            {"role": "assistant", "content": random.choice(
                [
                    "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω ph√°p l√Ω c·ªßa b·∫°n. H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v√†o √¥ b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu tr√≤ chuy·ªán v·ªõi t√¥i.",
                    "Ch√†o b·∫°n! B·∫°n c·∫ßn t√¥i gi√∫p g√¨ kh√¥ng? T√¥i c√≥ th·ªÉ tr·∫£ l·ªùi m·ªçi c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ lu·∫≠t giao th√¥ng ƒë∆∞·ªùng b·ªô c·ªßa b·∫°n.",
                    "B·∫°n mu·ªën bi·∫øt g√¨ v·ªÅ lu·∫≠t giao th√¥ng ƒë∆∞·ªùng b·ªô? H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v√†o √¥ b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu tr√≤ chuy·ªán v·ªõi t√¥i.",
            ])}
        ]
        msgs.add_ai_message(st.session_state.messages[0]["content"])
    
    for msg in st.session_state['messages']:
        with st.chat_message(msg["role"]):
            # response = st.markdown_stream(response_generator(msg["content"]))
            st.markdown(msg["content"])
    return msgs

def user_input(msgs, model_choice, new_retriever, old_retriever):
    if prompt:= st.chat_input("H√£y h·ªèi t√¥i b·∫•t c·ª© ƒëi·ªÅu g√¨ v·ªÅ lu·∫≠t giao th√¥ng ƒë∆∞·ªùng b·ªô!"):
        st.session_state['messages'].append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)   
        msgs.add_user_message(prompt)
        router = get_router(prompt, model_choice)
        router, status = router.split(",")
        router = router.strip(" ")
        status = status.strip(" ")
        # st.markdown(router)
        # st.markdown(status)
        transform_prompt = query_transform(prompt, model_choice)
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            timer_placeholder = st.empty()
            start_time = time.time()  # B·∫Øt ƒë·∫ßu ƒëo th·ªùi gian
            with st.spinner("ƒêang t√¨m ki·∫øm th√¥ng tin..."):
                def update_timer():
                    while True:
                        elapsed_time = time.time() - start_time
                        timer_placeholder.caption(f"‚è±Ô∏è ƒêang x·ª≠ l√Ω: {elapsed_time:.2f} gi√¢y")
                        time.sleep(0.1)

                import threading
                timer_thread = threading.Thread(target=update_timer, daemon=True)
                timer_thread.start()
                chat_history = [
                    {"role": msg["role"], "content": msg["content"]}
                    for msg in st.session_state.messages[:-1]
                ]
                if router == "yes":
                    if status == "new":
                        context = new_retriever.invoke(transform_prompt)
                        
                    elif status == "old":
                        context = old_retriever.invoke(transform_prompt)

                    response = legal_response(msgs, model_choice, context, chat_history)
                        
                elif router == "no":
                    response = normal_response(transform_prompt, model_choice, chat_history)
                    
                # elif router == "history":
                #     response = history_response(prompt, model_choice, chat_history)
                    
                else:
                    response = random.choice([
                    "C√¢u h·ªèi c·ªßa b·∫°n n·∫±m kh√¥ng n·∫±m trong ph·∫°m vi v·ªÅ lu·∫≠t giao th√¥ng ƒë∆∞·ªùng b·ªô. H√£y nh·∫≠p c√¢u h·ªèi kh√°c ƒë·ªÉ t√¥i gi√∫p b·∫°n nh√©!",
                    "Xin l·ªói, c√¢u h·ªèi n√†y kh√¥ng n·∫±m trong ph·∫°m vi c·ªßa t√¥i. H√£y nh·∫≠p c√¢u h·ªèi kh√°c ƒë·ªÉ t√¥i gi√∫p b·∫°n nh√©!",
                    "Ki·∫øn th·ª©c c·ªßa t√¥i ch·ªâ gi·ªõi h·∫°n trong lƒ©nh v·ª±c lu·∫≠t giao th√¥ng ƒë∆∞·ªùng b·ªô. H√£y nh·∫≠p c√¢u h·ªèi kh√°c ƒë·ªÉ t√¥i gi√∫p b·∫°n nh√©!",
                ])  
                response_content = ""
                for chunk in response:
                    for char in chunk:
                        response_content += char
                        response_placeholder.markdown(response_content)
                end_time = time.time()  # K·∫øt th√∫c ƒëo th·ªùi gian
                elapsed_time = end_time - start_time    
                    # response = prompt
                # response = st.write_stream(response_generator(response))
                st.session_state['messages'].append({"role": "assistant", "content": response})
                msgs.add_ai_message(response)
                # st.markdown(response)
                
                elapsed_time = time.time() - start_time
                timer_placeholder.caption(f"‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω: {elapsed_time:.2f} gi√¢y")
def main():
    setup_page()
    model_choice = setup_sidebar()
    new_retriever = postgres_retriever(collection_name="vectordb", database_name="postgres")
    old_retriever = postgres_retriever(collection_name="old_vectordb", database_name="old_law")
    msgs = setup_chat_interface(model_choice)
    user_input(msgs, model_choice, new_retriever, old_retriever)
    
if __name__ == "__main__":
    main()