{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Read and Save method***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data from the docx file\n",
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    content = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        if paragraph.text.strip():\n",
    "            paragraph = paragraph.text.lower()\n",
    "            content.append(paragraph.strip())\n",
    "    return content\n",
    "\n",
    "def save_to_json(data, output_file):\n",
    "    with open(output_file, mode='w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***METHOD***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Saving data to data folder***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is saved to: ../data/formatted_data.json\n"
     ]
    }
   ],
   "source": [
    "# Load documents\n",
    "document = read_docx('../data/*.docx')\n",
    "\n",
    "# Calling chunker\n",
    "chunker = chunkMethod(raw_data=document)\n",
    "data = chunker.semantic_chunk(\n",
    "        model_name=\"bkai-foundation-models/vietnamese-bi-encoder\",\n",
    "        similarity_threshold=0.8,\n",
    "        group_max_size=300\n",
    ")\n",
    "\n",
    "# Main script\n",
    "input_file = \"../data/law.docx\" \n",
    "output_file = \"../data/formatted_data.json\"\n",
    "\n",
    "# Đọc dữ liệu\n",
    "raw_data = read_docx(input_file)\n",
    "chunker = chunkMethod(raw_data=raw_data)\n",
    "chunked_data = chunker.recursive_chunk()\n",
    "\n",
    "# Xuất ra JSON\n",
    "save_to_json(chunked_data, output_file)\n",
    "print(f\"Data is saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Load in json data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_load = pd.read_json(\"../data/formatted_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Preprocessing data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'chapter':[], 'chapter_title':[], 'article':[], 'title':[], 'lines':[]}\n",
    "for i in range(len(json_load)):\n",
    "    chapter = json_load[json_load.index == i]['chapter'].values[0]\n",
    "    chapter_title = json_load[json_load.index == i]['chapter_title'].values[0]\n",
    "    chapter_ariticles = json_load[json_load.index == i]['chapter_articles'].values[0]\n",
    "    for article in chapter_ariticles:\n",
    "        dict['chapter'].append(chapter)\n",
    "        dict['chapter_title'].append(chapter_title)\n",
    "        dict['article'].append(article['article'])\n",
    "        dict['title'].append(article['title'])\n",
    "        dict['lines'].append(article['lines'])\n",
    "        \n",
    "dict = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_dict = {'chapter':[], 'chapter_title':[], 'article':[], 'title':[], 'context':[]}\n",
    "for i in range(len(dict)):\n",
    "    chapter = dict[dict.index == i]['chapter'].values[0]\n",
    "    chapter_title = dict[dict.index == i]['chapter_title'].values[0]\n",
    "    article = dict[dict.index == i]['article'].values[0]\n",
    "    title = dict[dict.index == i]['title'].values[0]\n",
    "    for line in dict[dict.index == i]['lines'].values[0]:\n",
    "        context_dict['chapter'].append(chapter)\n",
    "        context_dict['chapter_title'].append(chapter_title)\n",
    "        context_dict['article'].append(article)\n",
    "        context_dict['title'].append(title)\n",
    "        context_dict['context'].append(line)\n",
    "        \n",
    "context_dict = pd.DataFrame(context_dict)\n",
    "get_context = context_dict['context'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Chunking method***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chunkMethod:\n",
    "    def __init__(self,raw_data: list,\n",
    "                chunk_size: int = 300,\n",
    "                chunk_overlap: int = 20):\n",
    "        self.raw_data = raw_data\n",
    "\n",
    "    def document_based_chunk(self):\n",
    "        data = []\n",
    "        current_title = None\n",
    "        current_chapter = None\n",
    "        current_title = None\n",
    "        current_articles = []\n",
    "        \n",
    "        for idx, line in enumerate(self.raw_data):\n",
    "            chapter_match = re.match(r\"(chương\\s+\\w+)\\s*(.*)\", line)\n",
    "            if chapter_match:\n",
    "                if current_chapter and current_articles:\n",
    "                    data.append({\n",
    "                        \"chapter\": current_chapter,\n",
    "                        \"chapter_title\": current_title,\n",
    "                        \"chapter_articles\": current_articles\n",
    "                    })\n",
    "\n",
    "                current_chapter = chapter_match.group(1)\n",
    "                current_title = self.raw_data[idx + 1] if idx + 1 < len(self.raw_data) else \"\"\n",
    "                current_articles = []\n",
    "                \n",
    "            elif re.match(r\"điều\\s+\\d+\\.\", line):\n",
    "                article_match = re.match(r\"(điều\\s+\\d+\\.)(.*)\", line)\n",
    "                if article_match:\n",
    "                    current_articles.append({\n",
    "                        \"article\": article_match.group(1).strip(),\n",
    "                        \"title\": article_match.group(2).strip(),\n",
    "                        \"lines\": []\n",
    "                    })\n",
    "                    \n",
    "            else:\n",
    "                if current_articles:\n",
    "                    current_articles[-1][\"lines\"].append(line.strip())\n",
    "        \n",
    "        if current_chapter and current_articles:\n",
    "            data.append({\n",
    "                \"chapter\": current_chapter,\n",
    "                \"chapter_title\": current_title,\n",
    "                \"chapter_articles\": current_articles\n",
    "            })\n",
    "        \n",
    "        return data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
